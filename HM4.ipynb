{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "HM4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O259JzSf6bc_"
      },
      "source": [
        "# Home 4: Build a CNN for image recognition.\n",
        "\n",
        "### Name: [Prajwal Prakash]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKmCb-ey6bdK"
      },
      "source": [
        "## 0. You will do the following:\n",
        "\n",
        "1. Read, complete, and run the code.\n",
        "\n",
        "2. **Make substantial improvements** to maximize the accurcy.\n",
        "    \n",
        "3. Convert the .IPYNB file to .HTML file.\n",
        "\n",
        "    * The HTML file must contain the code and the output after execution.\n",
        "    \n",
        "    * Missing **the output after execution** will not be graded.\n",
        "    \n",
        "4. Upload this .HTML file to your Google Drive, Dropbox, or Github repo. (If you submit the file to Google Drive or Dropbox, you must make the file \"open-access\". The delay caused by \"deny of access\" may result in late penalty.)\n",
        "\n",
        "4. Submit the link to this .HTML file to Canvas.\n",
        "\n",
        "    * Example: https://github.com/wangshusen/CS583-2020S/blob/master/homework/HM4/HM4.html\n",
        "\n",
        "\n",
        "## Requirements:\n",
        "\n",
        "1. You can use whatever CNN architecture, including VGG, Inception, and ResNet. However, you must build the networks layer by layer. You must NOT import the archetectures from ```keras.applications```.\n",
        "\n",
        "2. Make sure ```BatchNormalization``` is between a ```Conv```/```Dense``` layer and an ```activation``` layer.\n",
        "\n",
        "3. If you want to regularize a ```Conv```/```Dense``` layer, you should place a ```Dropout``` layer **before** the ```Conv```/```Dense``` layer.\n",
        "\n",
        "4. An accuracy above 70% is considered reasonable. An accuracy above 80% is considered good. Without data augmentation, achieving 80% accuracy is difficult.\n",
        "\n",
        "\n",
        "## Google Colab\n",
        "\n",
        "- If you do not have GPU, the training of a CNN can be slow. Google Colab is a good option.\n",
        "\n",
        "- Keep in mind that you must download it as an IPYNB file and then use IPython Notebook to convert it to HTML.\n",
        "\n",
        "- Also keep in mind that the IPYNB and HTML files must contain the outputs. (Otherwise, the instructor will not be able to know the correctness and performance.) Do the followings to keep the outputs.\n",
        "\n",
        "- In Colab, go to ```Runtime``` --> ```Change runtime type``` --> Do NOT check ```Omit code cell output when saving this notebook```. In this way, the downloaded IPYNB file contains the outputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJQ78thk6bdM"
      },
      "source": [
        "## 1. Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6t0Bcsp6bdM"
      },
      "source": [
        "### 1.1. Load data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gU0TGU6C6bdN",
        "outputId": "0bb88f72-2076-4abd-82ea-0d7c464c6187"
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "import numpy as np\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "print('shape of x_train: ' + str(x_train.shape))\n",
        "print('shape of y_train: ' + str(y_train.shape))\n",
        "print('shape of x_test: ' + str(x_test.shape))\n",
        "print('shape of y_test: ' + str(y_test.shape))\n",
        "print('number of classes: ' + str(np.max(y_train) - np.min(y_train) + 1))\n",
        "numberOfClasses = np.max(y_train) - np.min(y_train) + 1"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of x_train: (50000, 32, 32, 3)\n",
            "shape of y_train: (50000, 1)\n",
            "shape of x_test: (10000, 32, 32, 3)\n",
            "shape of y_test: (10000, 1)\n",
            "number of classes: 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AX9w1QqX6bdP"
      },
      "source": [
        "### 1.2. One-hot encode the labels\n",
        "\n",
        "In the input, a label is a scalar in $\\{0, 1, \\cdots , 9\\}$. One-hot encode transform such a scalar to a $10$-dim vector. E.g., a scalar ```y_train[j]=3``` is transformed to the vector ```y_train_vec[j]=[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]```.\n",
        "\n",
        "1. Define a function ```to_one_hot``` that transforms an $n\\times 1$ array to a $n\\times 10$ matrix.\n",
        "\n",
        "2. Apply the function to ```y_train``` and ```y_test```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQ6LUoSa6bdQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6449d6e6-2209-439e-d56f-2d9e130d11b4"
      },
      "source": [
        "def to_one_hot(y, num_class=10):\n",
        "  final = []\n",
        "  for value in y[ : , 0]:\n",
        "    a = np.zeros(num_class)\n",
        "    a[value] = 1\n",
        "    final.append(a)\n",
        "  return np.array(final)\n",
        "\n",
        "y_train_vec = to_one_hot(y_train)\n",
        "y_test_vec = to_one_hot(y_test)\n",
        "\n",
        "print('Shape of y_train_vec: ' + str(y_train_vec.shape))\n",
        "print('Shape of y_test_vec: ' + str(y_test_vec.shape))\n",
        "\n",
        "print(y_train[0])\n",
        "print(y_train_vec[0])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of y_train_vec: (50000, 10)\n",
            "Shape of y_test_vec: (10000, 10)\n",
            "[6]\n",
            "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdWUoWEw6bdR"
      },
      "source": [
        "#### Remark: the outputs should be\n",
        "* Shape of y_train_vec: (50000, 10)\n",
        "* Shape of y_test_vec: (10000, 10)\n",
        "* [6]\n",
        "* [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ef4un7c6bdS"
      },
      "source": [
        "### 1.3. Randomly partition the training set to training and validation sets\n",
        "\n",
        "Randomly partition the 50K training samples to 2 sets:\n",
        "* a training set containing 40K samples\n",
        "* a validation set containing 10K samples\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvaj1Fnk6bdT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5455d4f-b6e1-444a-f8a2-61f0ba16d3d7"
      },
      "source": [
        "rand_indices = np.random.permutation(50000)\n",
        "train_indices = rand_indices[0:40000]\n",
        "valid_indices = rand_indices[40000:50000]\n",
        "\n",
        "x_val = x_train[valid_indices, :]\n",
        "y_val = y_train_vec[valid_indices, :]\n",
        "\n",
        "x_tr = x_train[train_indices, :]\n",
        "y_tr = y_train_vec[train_indices, :]\n",
        "\n",
        "print('Shape of x_tr: ' + str(x_tr.shape))\n",
        "print('Shape of y_tr: ' + str(y_tr.shape))\n",
        "print('Shape of x_val: ' + str(x_val.shape))\n",
        "print('Shape of y_val: ' + str(y_val.shape))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of x_tr: (40000, 32, 32, 3)\n",
            "Shape of y_tr: (40000, 10)\n",
            "Shape of x_val: (10000, 32, 32, 3)\n",
            "Shape of y_val: (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BfdhUKe6bdU"
      },
      "source": [
        "## 2. Build a CNN and tune its hyper-parameters\n",
        "\n",
        "1. Build a convolutional neural network model\n",
        "2. Use the validation data to tune the hyper-parameters (e.g., network structure, and optimization algorithm)\n",
        "    * Do NOT use test data for hyper-parameter tuning!!!\n",
        "3. Try to achieve a validation accuracy as high as possible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQw7uJFH6bdU"
      },
      "source": [
        "### Remark: \n",
        "\n",
        "The following CNN is just an example. You are supposed to make **substantial improvements** such as:\n",
        "* Add more layers.\n",
        "* Use regularizations, e.g., dropout.\n",
        "* Use batch normalization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFqIWWfL6bdV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e903aab-9032-442d-908f-723cbadc791f"
      },
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from keras.models import Sequential\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "# model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(MaxPooling2D((2, 2)))\n",
        "# model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "# model.add(Dropout(0.5))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "# model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_26 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization_30 (Batc (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_27 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_31 (Batc (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_28 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_32 (Batc (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_29 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_33 (Batc (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_30 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_34 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_31 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_35 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "batch_normalization_36 (Batc (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 552,874\n",
            "Trainable params: 551,722\n",
            "Non-trainable params: 1,152\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWqx3FeG6bdW"
      },
      "source": [
        "from keras import optimizers\n",
        "\n",
        "learning_rate = 0.001 # to be tuned!\n",
        "\n",
        "model.compile(loss='CategoricalCrossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=learning_rate),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4XKKaV8xmjR",
        "outputId": "a61b0584-7362-4eb0-85cb-3481709b6a0d"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(width_shift_range = 0.1, height_shift_range = 0.1, horizontal_flip = True, )\n",
        "# it_train = datagen.flow(x_tr, y_tr, 512)\n",
        "datagen.fit(x_tr)\n",
        "\n",
        "history = model.fit(datagen.flow(x_tr, y_tr, batch_size=512),\n",
        "    epochs=100,\n",
        "    validation_data=(x_val, y_val))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "79/79 [==============================] - 19s 224ms/step - loss: 2.3330 - acc: 0.2732 - val_loss: 1.8965 - val_acc: 0.3142\n",
            "Epoch 2/100\n",
            "79/79 [==============================] - 17s 218ms/step - loss: 1.6260 - acc: 0.4401 - val_loss: 1.3619 - val_acc: 0.5119\n",
            "Epoch 3/100\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 1.3781 - acc: 0.5259 - val_loss: 1.2727 - val_acc: 0.5575\n",
            "Epoch 4/100\n",
            "79/79 [==============================] - 17s 219ms/step - loss: 1.2178 - acc: 0.5785 - val_loss: 1.0756 - val_acc: 0.6124\n",
            "Epoch 5/100\n",
            "79/79 [==============================] - 17s 219ms/step - loss: 1.0685 - acc: 0.6285 - val_loss: 0.9210 - val_acc: 0.6765\n",
            "Epoch 6/100\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 0.9935 - acc: 0.6538 - val_loss: 0.9203 - val_acc: 0.6812\n",
            "Epoch 7/100\n",
            "79/79 [==============================] - 17s 218ms/step - loss: 0.9249 - acc: 0.6746 - val_loss: 0.7932 - val_acc: 0.7164\n",
            "Epoch 8/100\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 0.8456 - acc: 0.7042 - val_loss: 0.7096 - val_acc: 0.7499\n",
            "Epoch 9/100\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 0.8050 - acc: 0.7224 - val_loss: 0.9364 - val_acc: 0.6865\n",
            "Epoch 10/100\n",
            "79/79 [==============================] - 17s 223ms/step - loss: 0.7709 - acc: 0.7321 - val_loss: 0.7164 - val_acc: 0.7495\n",
            "Epoch 11/100\n",
            "79/79 [==============================] - 17s 218ms/step - loss: 0.7497 - acc: 0.7433 - val_loss: 0.9428 - val_acc: 0.6939\n",
            "Epoch 12/100\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 0.7016 - acc: 0.7586 - val_loss: 0.6898 - val_acc: 0.7638\n",
            "Epoch 13/100\n",
            "79/79 [==============================] - 17s 218ms/step - loss: 0.6753 - acc: 0.7677 - val_loss: 0.6248 - val_acc: 0.7834\n",
            "Epoch 14/100\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 0.6662 - acc: 0.7705 - val_loss: 0.6389 - val_acc: 0.7811\n",
            "Epoch 15/100\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 0.6421 - acc: 0.7779 - val_loss: 0.5807 - val_acc: 0.7969\n",
            "Epoch 16/100\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 0.6284 - acc: 0.7833 - val_loss: 0.5904 - val_acc: 0.7974\n",
            "Epoch 17/100\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 0.6199 - acc: 0.7856 - val_loss: 0.8530 - val_acc: 0.7458\n",
            "Epoch 18/100\n",
            "79/79 [==============================] - 17s 219ms/step - loss: 0.5981 - acc: 0.7938 - val_loss: 0.5781 - val_acc: 0.8031\n",
            "Epoch 19/100\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 0.5890 - acc: 0.7972 - val_loss: 0.5404 - val_acc: 0.8106\n",
            "Epoch 20/100\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 0.5758 - acc: 0.8056 - val_loss: 0.5563 - val_acc: 0.8101\n",
            "Epoch 21/100\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 0.5523 - acc: 0.8087 - val_loss: 0.6037 - val_acc: 0.7944\n",
            "Epoch 22/100\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 0.5418 - acc: 0.8153 - val_loss: 0.5966 - val_acc: 0.8026\n",
            "Epoch 23/100\n",
            "79/79 [==============================] - 17s 219ms/step - loss: 0.5486 - acc: 0.8115 - val_loss: 0.4949 - val_acc: 0.8304\n",
            "Epoch 24/100\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 0.5229 - acc: 0.8210 - val_loss: 0.5142 - val_acc: 0.8246\n",
            "Epoch 25/100\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 0.5079 - acc: 0.8224 - val_loss: 0.5267 - val_acc: 0.8208\n",
            "Epoch 26/100\n",
            "79/79 [==============================] - 18s 226ms/step - loss: 0.5070 - acc: 0.8254 - val_loss: 0.5673 - val_acc: 0.8115\n",
            "Epoch 27/100\n",
            "79/79 [==============================] - 18s 222ms/step - loss: 0.5008 - acc: 0.8285 - val_loss: 0.5139 - val_acc: 0.8263\n",
            "Epoch 28/100\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 0.4999 - acc: 0.8289 - val_loss: 0.4888 - val_acc: 0.8353\n",
            "Epoch 29/100\n",
            "79/79 [==============================] - 18s 222ms/step - loss: 0.4856 - acc: 0.8350 - val_loss: 0.5537 - val_acc: 0.8181\n",
            "Epoch 30/100\n",
            "79/79 [==============================] - 17s 219ms/step - loss: 0.4739 - acc: 0.8389 - val_loss: 0.5009 - val_acc: 0.8347\n",
            "Epoch 31/100\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 0.4735 - acc: 0.8396 - val_loss: 0.5722 - val_acc: 0.8120\n",
            "Epoch 32/100\n",
            "79/79 [==============================] - 18s 222ms/step - loss: 0.4593 - acc: 0.8432 - val_loss: 0.5333 - val_acc: 0.8182\n",
            "Epoch 33/100\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 0.4668 - acc: 0.8386 - val_loss: 0.4732 - val_acc: 0.8438\n",
            "Epoch 34/100\n",
            "79/79 [==============================] - 17s 219ms/step - loss: 0.4648 - acc: 0.8401 - val_loss: 0.4888 - val_acc: 0.8360\n",
            "Epoch 35/100\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 0.4535 - acc: 0.8447 - val_loss: 0.4504 - val_acc: 0.8500\n",
            "Epoch 36/100\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 0.4369 - acc: 0.8486 - val_loss: 0.4842 - val_acc: 0.8384\n",
            "Epoch 37/100\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 0.4343 - acc: 0.8499 - val_loss: 0.5695 - val_acc: 0.8207\n",
            "Epoch 38/100\n",
            "79/79 [==============================] - 17s 219ms/step - loss: 0.4354 - acc: 0.8526 - val_loss: 0.5206 - val_acc: 0.8309\n",
            "Epoch 39/100\n",
            "79/79 [==============================] - 18s 224ms/step - loss: 0.4287 - acc: 0.8541 - val_loss: 0.5167 - val_acc: 0.8296\n",
            "Epoch 40/100\n",
            "79/79 [==============================] - 18s 222ms/step - loss: 0.4264 - acc: 0.8544 - val_loss: 0.5139 - val_acc: 0.8354\n",
            "Epoch 41/100\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 0.4282 - acc: 0.8552 - val_loss: 0.4889 - val_acc: 0.8446\n",
            "Epoch 42/100\n",
            "79/79 [==============================] - 17s 219ms/step - loss: 0.4290 - acc: 0.8545 - val_loss: 0.4648 - val_acc: 0.8474\n",
            "Epoch 43/100\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 0.4152 - acc: 0.8564 - val_loss: 0.4381 - val_acc: 0.8518\n",
            "Epoch 44/100\n",
            "79/79 [==============================] - 18s 221ms/step - loss: 0.4062 - acc: 0.8592 - val_loss: 0.4911 - val_acc: 0.8380\n",
            "Epoch 45/100\n",
            "79/79 [==============================] - 17s 219ms/step - loss: 0.4074 - acc: 0.8619 - val_loss: 0.4613 - val_acc: 0.8461\n",
            "Epoch 46/100\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 0.3985 - acc: 0.8612 - val_loss: 0.4633 - val_acc: 0.8488\n",
            "Epoch 47/100\n",
            "79/79 [==============================] - 17s 219ms/step - loss: 0.3996 - acc: 0.8621 - val_loss: 0.3962 - val_acc: 0.8673\n",
            "Epoch 48/100\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 0.3969 - acc: 0.8644 - val_loss: 0.4269 - val_acc: 0.8581\n",
            "Epoch 49/100\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 0.3927 - acc: 0.8643 - val_loss: 0.4892 - val_acc: 0.8426\n",
            "Epoch 50/100\n",
            "79/79 [==============================] - 18s 223ms/step - loss: 0.3849 - acc: 0.8682 - val_loss: 0.4615 - val_acc: 0.8530\n",
            "Epoch 51/100\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 0.3829 - acc: 0.8686 - val_loss: 0.5356 - val_acc: 0.8344\n",
            "Epoch 52/100\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 0.3801 - acc: 0.8681 - val_loss: 0.3982 - val_acc: 0.8670\n",
            "Epoch 53/100\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 0.3821 - acc: 0.8696 - val_loss: 0.4230 - val_acc: 0.8608\n",
            "Epoch 54/100\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 0.3803 - acc: 0.8689 - val_loss: 0.4489 - val_acc: 0.8537\n",
            "Epoch 55/100\n",
            "79/79 [==============================] - 17s 219ms/step - loss: 0.3803 - acc: 0.8690 - val_loss: 0.4195 - val_acc: 0.8625\n",
            "Epoch 56/100\n",
            "79/79 [==============================] - 18s 222ms/step - loss: 0.3786 - acc: 0.8702 - val_loss: 0.3966 - val_acc: 0.8695\n",
            "Epoch 57/100\n",
            "79/79 [==============================] - 18s 223ms/step - loss: 0.3671 - acc: 0.8733 - val_loss: 0.4947 - val_acc: 0.8431\n",
            "Epoch 58/100\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 0.3667 - acc: 0.8746 - val_loss: 0.4422 - val_acc: 0.8589\n",
            "Epoch 59/100\n",
            "79/79 [==============================] - 18s 222ms/step - loss: 0.3661 - acc: 0.8749 - val_loss: 0.4780 - val_acc: 0.8455\n",
            "Epoch 60/100\n",
            "79/79 [==============================] - 18s 222ms/step - loss: 0.3609 - acc: 0.8758 - val_loss: 0.4711 - val_acc: 0.8437\n",
            "Epoch 61/100\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 0.3596 - acc: 0.8768 - val_loss: 0.4127 - val_acc: 0.8637\n",
            "Epoch 62/100\n",
            "79/79 [==============================] - 17s 219ms/step - loss: 0.3608 - acc: 0.8779 - val_loss: 0.4448 - val_acc: 0.8552\n",
            "Epoch 63/100\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 0.3538 - acc: 0.8793 - val_loss: 0.4661 - val_acc: 0.8504\n",
            "Epoch 64/100\n",
            "79/79 [==============================] - 17s 219ms/step - loss: 0.3484 - acc: 0.8809 - val_loss: 0.4560 - val_acc: 0.8542\n",
            "Epoch 65/100\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 0.3454 - acc: 0.8797 - val_loss: 0.4341 - val_acc: 0.8609\n",
            "Epoch 66/100\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 0.3437 - acc: 0.8807 - val_loss: 0.3894 - val_acc: 0.8726\n",
            "Epoch 67/100\n",
            "79/79 [==============================] - 18s 221ms/step - loss: 0.3428 - acc: 0.8825 - val_loss: 0.4193 - val_acc: 0.8634\n",
            "Epoch 68/100\n",
            "79/79 [==============================] - 17s 219ms/step - loss: 0.3368 - acc: 0.8835 - val_loss: 0.4252 - val_acc: 0.8604\n",
            "Epoch 69/100\n",
            "79/79 [==============================] - 17s 219ms/step - loss: 0.3455 - acc: 0.8831 - val_loss: 0.4156 - val_acc: 0.8648\n",
            "Epoch 70/100\n",
            "79/79 [==============================] - 17s 219ms/step - loss: 0.3410 - acc: 0.8828 - val_loss: 0.4063 - val_acc: 0.8690\n",
            "Epoch 71/100\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 0.3375 - acc: 0.8827 - val_loss: 0.4376 - val_acc: 0.8579\n",
            "Epoch 72/100\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 0.3298 - acc: 0.8851 - val_loss: 0.4712 - val_acc: 0.8578\n",
            "Epoch 73/100\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 0.3298 - acc: 0.8873 - val_loss: 0.3861 - val_acc: 0.8762\n",
            "Epoch 74/100\n",
            "79/79 [==============================] - 18s 222ms/step - loss: 0.3251 - acc: 0.8873 - val_loss: 0.5929 - val_acc: 0.8179\n",
            "Epoch 75/100\n",
            "79/79 [==============================] - 18s 222ms/step - loss: 0.3304 - acc: 0.8857 - val_loss: 0.5054 - val_acc: 0.8404\n",
            "Epoch 76/100\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 0.3390 - acc: 0.8830 - val_loss: 0.4142 - val_acc: 0.8686\n",
            "Epoch 77/100\n",
            "79/79 [==============================] - 18s 221ms/step - loss: 0.3298 - acc: 0.8864 - val_loss: 0.4396 - val_acc: 0.8578\n",
            "Epoch 78/100\n",
            "79/79 [==============================] - 17s 219ms/step - loss: 0.3240 - acc: 0.8878 - val_loss: 0.4420 - val_acc: 0.8617\n",
            "Epoch 79/100\n",
            "79/79 [==============================] - 17s 219ms/step - loss: 0.3256 - acc: 0.8864 - val_loss: 0.4241 - val_acc: 0.8641\n",
            "Epoch 80/100\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 0.3232 - acc: 0.8903 - val_loss: 0.3848 - val_acc: 0.8778\n",
            "Epoch 81/100\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 0.3246 - acc: 0.8884 - val_loss: 0.4399 - val_acc: 0.8634\n",
            "Epoch 82/100\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 0.3133 - acc: 0.8926 - val_loss: 0.4052 - val_acc: 0.8690\n",
            "Epoch 83/100\n",
            "79/79 [==============================] - 17s 219ms/step - loss: 0.3154 - acc: 0.8921 - val_loss: 0.4229 - val_acc: 0.8660\n",
            "Epoch 84/100\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 0.3243 - acc: 0.8901 - val_loss: 0.4623 - val_acc: 0.8598\n",
            "Epoch 85/100\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 0.3071 - acc: 0.8919 - val_loss: 0.4352 - val_acc: 0.8616\n",
            "Epoch 86/100\n",
            "79/79 [==============================] - 18s 221ms/step - loss: 0.3155 - acc: 0.8907 - val_loss: 0.4047 - val_acc: 0.8692\n",
            "Epoch 87/100\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 0.3142 - acc: 0.8916 - val_loss: 0.3847 - val_acc: 0.8758\n",
            "Epoch 88/100\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 0.3060 - acc: 0.8948 - val_loss: 0.4067 - val_acc: 0.8709\n",
            "Epoch 89/100\n",
            "79/79 [==============================] - 17s 218ms/step - loss: 0.3093 - acc: 0.8938 - val_loss: 0.3959 - val_acc: 0.8733\n",
            "Epoch 90/100\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 0.3069 - acc: 0.8950 - val_loss: 0.4239 - val_acc: 0.8674\n",
            "Epoch 91/100\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 0.3060 - acc: 0.8965 - val_loss: 0.4223 - val_acc: 0.8658\n",
            "Epoch 92/100\n",
            "79/79 [==============================] - 18s 222ms/step - loss: 0.3064 - acc: 0.8944 - val_loss: 0.3949 - val_acc: 0.8720\n",
            "Epoch 93/100\n",
            "79/79 [==============================] - 18s 221ms/step - loss: 0.3026 - acc: 0.8969 - val_loss: 0.4034 - val_acc: 0.8710\n",
            "Epoch 94/100\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 0.2997 - acc: 0.8967 - val_loss: 0.4205 - val_acc: 0.8704\n",
            "Epoch 95/100\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 0.2950 - acc: 0.8974 - val_loss: 0.3971 - val_acc: 0.8734\n",
            "Epoch 96/100\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 0.3015 - acc: 0.8964 - val_loss: 0.3635 - val_acc: 0.8846\n",
            "Epoch 97/100\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 0.2960 - acc: 0.8983 - val_loss: 0.3898 - val_acc: 0.8754\n",
            "Epoch 98/100\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 0.2993 - acc: 0.8971 - val_loss: 0.4296 - val_acc: 0.8727\n",
            "Epoch 99/100\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 0.2914 - acc: 0.9008 - val_loss: 0.4072 - val_acc: 0.8735\n",
            "Epoch 100/100\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 0.2889 - acc: 0.9013 - val_loss: 0.4468 - val_acc: 0.8657\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wek1LLUe6bdX"
      },
      "source": [
        "# history = model.fit(datagen, x_tr, y_tr, batch_size=512, epochs=100, validation_data=(x_val, y_val)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4XydV_66bdY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "7d3a3def-d43d-445e-cdc2-a4c21eb2e32a"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU1fn48c+TsIQQZFeRQBIk7EuACIpVcWtRW3CtILXghgKudUNp61bq12rr0lL7o3VBSAW3IipuIC4tLgQEhAAmQkAWIYBAQthCnt8fZ2YySSYh22SS3Of9es0rc8+9c++5M3Cfe5Z7jqgqxhhjvCsq0hkwxhgTWRYIjDHG4ywQGGOMx1kgMMYYj7NAYIwxHtco0hmorHbt2mliYmKks2GMMfXK0qVLd6pq+1Dr6l0gSExMJD09PdLZMMaYekVENpa1zqqGjDHG4ywQGGOMx1kgMMYYj7NAYIwxHmeBwBhjPC6sgUBEhovIOhHJEpHJIdYniMhCEVkpIh+LSHw482OMMfVRWhokJkJUlPubllaz+w9bIBCRaGAacAHQCxgtIr1KbPYE8JKq9gMeBh4NV36MMaY+8V/8ReDqq2HjRlB1f8ePr9lgEM4SwWAgS1XXq+phYDYwssQ2vYCPfO8XhVhvjDF1TvAdert27lXe++C7+LI+m5gIEyeWvviDCwDB8vNhypSaOx8J13wEInI5MFxVr/ctXw0MUdWbg7b5N/Clqj4tIpcCrwPtVHVXWftNTU1Ve6DMGFOT0tLchXXTJmjTxqXt3h36/a5d7kJd2Uun/zNV+WxZ+yssrMz2slRVU0Oti3Rj8V3AWSLyNXAWsAU4WnIjERkvIukikp6Tk1PbeTTG1EEVuSsvWZ8e6jMlq1527XKvst5D1S7k/s/U1L135841sx8Ib4ngNOBBVf2Zb/k+AFUN2Q4gInHAWlUtt8HYSgTG1D+VueOuyPvK3JX7t2vbFnJz4fDhmjuvSImNhenTYcyYin+mvBJBOMcaWgIki0gS7k5/FHBViYy1A3araiFwH/B8GPNjjKlhwRf4zp3hwgth/vziF/ySF+1dQRW/1Xlf0XvYUMetj/zfYUICTJ1auSBwLGELBKpaICI3A+8D0cDzqrpaRB4G0lV1HjAMeFREFPgUmBSu/BhjQqvq3XrJC/zGjfDss0X7rcpF2xQXzot/Mapar16DBg1SY7xq1izVhARVEfd31qyKb9+2rXsFvwe37C439qrMy/+9hfpej/Udj+VF/Zauem7LJYHtExJUJ0yo3O9bGbgb8JDX1bC1EYSLtREYr/HfsW/cWLpePLj+G2qmd4tXlfddlnzfuXPl7tCDS10XH7+YV3cOI7qwAFq2hAULYNCgmj+hEupyryFjDGU/OZqW5h4eKqs/uX+5Jnu31KQ4coGazcQwFnEv/wcoIi6tbVv3Eil6DwTW+zVuXHo7EVf1MvMlRRV27nSvwsKy32dnV66aZswY95nCjd/zBpcSnZQAy5ZBq1Zw3nnufSSVVVSoqy+rGjL1TVWqZ/zL0dGRrwKp6qsbazWfGL2cVypVlVLe+16tt+puaa0KelO7VytVNVZuVcurr6oef7zqJZeorllTfF1Ojurhw9X/h5CbqzpokGqLFqqrV7u0DRtcxo47TvXGG1Xfekt1/37VvXtVv/1Wdfly1aNHq39sLb9qKOIX9sq+LBCYuqSh1MH/gfv1Q87V1uyqcl15yTruOU1+pQr6BHfWTH13YaHqiBGqMTGqPXuqnnii6u7d1dtnXp7q9de7E+jdWzUuTjUqSvXaa1UnTlTt3t2tS05W/eST0Ps4dEj1D39QHTlSddIk1UcfVX3hBdW5c91nXnlF9corVZs3d1/MvHnFP79hg+rll7tjh/qCL77Y5bOaLBAYUwWzZqn26JSnQmEtXOQL9Uae1UWcpa3YXatB4Fe8FFj4OnqQdmm9u9y78hPbHNKJzV/UF/m1DozfHvoC/+237oIKqhddVP4X/eqrqp9/XrEfBFT//GfVpUvd/sePd+sKC1XT0lSvvlr1xRcrFiDWrlXt0cOd1OTJ7q5/xw7V225TbdzYXbgvvFD1kUdUu3Rxx77pJtWtW4v2sXKlakqKW9etm2qrVqG/5Pbt3R3/f/9bdn4OHlT98EPVBx5QfeIJ1Zkz3bGjolxJIvi4VWCBwJhyhLqrB9WT2KI/0lLTGK3RHKn0BfbP3KHrSNazWFTuds3J1ZmMCSTcwP+r0B14RYNQeVUy/Vih+dJMf+hxlruDbdxYNTVV9ccfS39Re/eqPv64aseORTs/4wx3R1zS2LGqzZqpDhumevLJZX/5e/YUXXSXLy97u61bVVu3Vj3tNNWCApd2550uDy+8oHrOOe69/666USPVn//cXexDef991ZYt3QV6wYLQ5xp8Xnl5qr/5TVFwa9/enXvjxq5K6T//Kdo2N1f1u+9U09Pdhf2zz1SPHCn73I5l3jz3/XTqpLpiRZV3Y4HAeF55VThNmoS+gD7FrXoUdxWtbDAQjup22gcSnuQ2bcb+UtudTKauopceRXQKj+gauutCzi61XXR06Xru4HPq0Oag/rfRWfp7HtK2bQqLdUkss0rmxx/dRbpDB9Vt21zavHnu4tajh7srzc5W3bXL3aW2dnXzevbZqu+9p/ryy275+uvdHblfVpbL8B13uM9FRakeOBA6D2lpbh/HHecudMF3vZs2qU6b5urtW7VyVULBF/a8PNXERPf5li3dtkeOqH71lerdd7v8xsSoPvVUUT37vn2qTz7p8te3r6uWqYyVK93+rrtOdcgQVwLZsaNy+6iKZctU4+NVZ8+u8i4sEJgG51h189WtwjmRrZpPjP6La/Ue/k8VdCZjNIqCCn1+IOmqoOP5hz7NLaqgGfTQnqwObNOT1bqVEzWHtnouH6qI6gM8oEcR7cCWwHaxzQr17T+uKL/R8Lnnig4+ceKxGxi//1516FB351yyuuLdd1UHDCjaX9Om7u/Ikapffll82ylT3LpnnilKu+YadwHetq0oWHzzTeh8XHqp6kknuaqe5s1VTzlF9YMP3MXff/fdubOrsw9VR//FF+5O3R/Igm3d6qqlQLV/f1ff7/+HMGKECwr1STXbCSwQmAbBf/GvyoW9sq8n+I0eIVq7kKWgei+PqoL+kckV+vx9TFUFbc92BdVzWaA/cLzm0lyvi5utKXytOdJOf5ATtReri+7c16xRBX2w9VOBO/rF419wO33kkdBfzNGjrvG0f3/Ve+5x2151Vdk9XebNU23Txl1458wp+wvPylJ97DHXALpyZdnHHjnSHbNJE1cdBK6eXVX166/d8iuvlP5sXp7bftIkt/zmm8XrsSZPVl23rnhpo7IKC1Wff161Xz938X/wQdX584uqlzzEAoGpt2rz4u9/Hc8Pup9m+iK/Lpb+HNfoIRprN9YWS09kg7Zne7HSyOJGZ+jy6IHFq2e2bHF34eAugJ06uUbVklJSVE891b3fu1f1hBPc3XGjRu7CWtJbb7l9+uuAHnVBS/v3V3377aIL6fLlquPGuXUDBriLbE3IzVX9v/9Tvfde1bvuchfwnTvduv373fEefrj05157za1buLAo7fXXXZ1/fn7N5M0EWCAwdd6sWarDTlqnx7E3LL1y4tmkT3OLfkNvPZnMcrd9jLu1gChNZl2xG9TurbfrHo7TBY1/pm3bFKqI6gUdvtbDMXHuwuq/4O7Z4+qg77+/9IkeOuTqzlNTy66ffuwxd9D1693FFVx1zYknqvbp43qXBDvzTBdUgksAr75a1NPl9NPdC1yVzZ13lt5HOCUkuBJKSVdd5b7Y6jSkmgqzQGDqtFmzVPvHrNUDNNUlDNKmHKiRi79wVE9lsU7nej1EYz1MI91PM/2EM1Q4GtiucWPVhDb79BLe0JlNr9N8YnQmY0I3tD75pPvQ3LmqGze6htaYGJfm7x/+xhtuuax+58eSne0+f911rrrl17926W+/7dInTy7a9ssvXdpf/lJ6P4cPqz77rGtkTE5221S3331V/OxnqgMHFk87eNA1EF93Xe3nx6MsEJhaV15jbu/WW7QRR4rSOaqfcbrm0lwV9DmuUSiscgDoQpb+k+v0B45XBT1AU/0bEzWBbB3H86qg98Y+E6i2+eTW11RjY92HW7ZUHTXKVeOEcviwaq9eqklJ7gGk445zPTq6dHF3+YWFrm97ixbVexrVX4XUvHnxvFx3nasmGj3a9er56U9dnutyw+dtt7nvN7gB2x/U5s+PXL48xgKBCbuSF/6yumR2JlsP0kQXcnbgwambeUYV9Ne8qA/xO1Vcb5tj3vGH6B8/uNU63SYdNJfm+kaTK3V8XJq24seiu/vCQtXhw92F6bvvVJ9+2n3wtNNUFy2q2MV74UINFCX89dv/+lfRha1zZ9frpTqecd+J/vGPxdP37nVVKvHxRV/EffdV71jh9uyzLp+bNhWlXXONC6K1WUXlcRYITFhUpSF3Mn9UBT1EY82gh57NQs2luc5nuEKhRlGg8xmuh2isg/mizIt/yGqbzEzXFbFdu7K7K6q6C1KLFq5aB9wj/JVtnPzLX9xdrd+hQy4AJCW5ff7jH5XbX0n797sLaHkXyu3bVT/+uOw++nXFokXuO/ngA7d88KDrtTRmTESz5TUWCEyNmTVLtU+nPTqYL0Je/NuSU04gKNRV9NLPOF3P4BPdSRtV0H3EaSc2BrZrzS7dQIIup58KR8u/+PutXevuktu2LburYzD/HfzEiTXXldB/5wuVf1CpIdu2zX0n/mcN/A+R+QODqRUWCEy1BN/5t2eHLqefKugQPi92oR/Fv7WAKD2FL0MGgv64PuU38qyCale+1U/5iY5hZvFg0lZ1fJy7WExsN6f8wcoOH3bdJWNi3AfLG6agpI0bq9dHvaSDB93wCz161Nw+G4LCQteOMXGiWz7jDPdEcw2NqmkqxgKBKe1vf3N9v0ONE6Ohq33as11X0kfzidFdtNaPGBZo1I0hXzfSSRX0BcaGDAR/4i49TCNtw86Q62Njg+74CwpcY2z37kXdC48edV0v+/RxDzHddZfrKw+uTn7z5lr56sq1YkXlgpFXDBnixgNatcr3j+FPkc6R51ggMMXt21c0bECvXoEhBsqr8z+eH3QVvXQ/zfQcFgQaeM/nfQUNDMPwFamaT4y2b7S7WE+h9m0K9Hs66ruNfxFyOIiQ1T6vv+4OPmOGW/Y/NXvGGS5ING3q7sDfeKM2vz1TFWPHuvabW25xPQlqY3weU4wFAlOcf/yXhx7SvLadVUFncLWmsqTMuv13uED300yH8ZGCahMO6noSNZ2B2o4duofj9C0u0hSWqYIuufrp4sf097Qpb0iDkgoL3YNaSUmuqyS4YYD91TlHj1r1Qn3hf9q5RYvQD5eZsLNAYIp173wn9jLd36qDznrpqLZvlqt/4q5AH/4vOUV/wZvFAsGluKEAbuPJYun+ceyXkaIFROm8x3yzLp1yiitpBNe/X3utuwhUtnfOO+8UHfDiiz05RkyD8J//FP2On34a6dx4kgUCj5s1q+h5qVjydD/N9G9MKnZRP449Oom/6hq661FEr2aGgmoc+3QzJ+kyUgLDMPurjZI6F+iP8X3cwg03FB3Q3yPns8/c8rZtrrFw7NjKZ97f7/+882z8mfrMN5heqRsEU2ssEHicv94fVC/jVVUoc7KUGPL1Q87VAqJ0NGn6F27Xo4gO8fXpL1WXv2iRewo2eBz5vDz3sNCvfuXGT2/TxvXqKTmEcUVZ9U/9d/iwa9eZOTPSOfGs8gKBuPX1R2pqqqanp0c6G3XPkSMQFQXR0YGktDSYMgU2biza7GVGcQ4f0YFtFBIdYkfQjHze4SLO5FP3mbjxyD+eZcyYSuRn0iT4+9/d+yFDYMYM6N69smdljKkhIrJUVVNDrYuq7cyYMJg9G9q0gUaNONKsBZsbJXCRvMPVVxcPAjEc4Oe8zRtcWmYQEIEDxDKp01vs7PETojt24Feb/li5IABwyy2QmAh//CP8978WBIypw8IaCERkuIisE5EsEZkcYn1nEVkkIl+LyEoRuTCc+WlwCgvdLf/o0dCvHysveYB/FNzA/qMxTGc8sZpXbPPhvEcc+3mNy0PuLiEBZs50lUQZm+I4YfUiWLcOWreufN569IANG+C++6BRo6qcnTGmloTtf6iIRAPTgPOBzcASEZmnqhlBm/0WeEVVnxWRXsB8IDFceWpQCgrg8svhzTfJGnY9F6yfRtbiJgCcyhV8zlDu41F+y9TARy7nNXbSlk85q9iuYmNh+nRK3/VHRUHz5uE+E2NMhIWzRDAYyFLV9ap6GJgNjCyxjQLH+d63BLaGMT8NyocP/g/efJPf8gjdPp5O1qYmgXVfcBoz+RV38meSWA/AeP4fo5jNe3FX8MKsxiQkuGqghIQygoAxxjPCWWbvCHwftLwZGFJimweBD0TkFqA5cF6oHYnIeGA8QOfOnWs8o3VObi689BLs3An79kHTpvDQQ9C4MeAagb/80xrOB2YwFkVK7eJeHuMS/sOfuZMV9OdBHuK9qAtp9NQTjBpjF35jTJFIV96OBl5U1T+LyGnATBHpo6qFwRup6nRgOrheQxHIZ+2aMMFd7QFiYuDgQT5odCHjX/oJmza5Gps/H11DHs3ZTHzIXWzjJKYyhUe5n0uYy6vNx3Fk2nSuGtu4Fk/EGFMfhLNqaAvQKWg53pcW7DrgFQBV/RyIAdqFMU913+LFLghMnsy/XypgaNt1AMx95Bs2bnQNuUePQk/WsJYeEKI04PdG5zvY1ud8eOABrsh93oKAMSakcJYIlgDJIpKECwCjgKtKbLMJOBd4UUR64gJBThjzVLcVFsJtt0GHDszpOoUbboomP78Te2hJH74ptmlP1vAxw0LupqjxNwb4IPz5NsbUa2ErEahqAXAz8D6wBtc7aLWIPCwiI3yb3QncICIrgJeBcVrfnnCrSTNnQno6dxx+jFHXx5GfDyCsog99gwJBHLl0YjNr6BlIE1/BwBp/jTGVFdY2AlWdj+sSGpz2+6D3GcDp4cxDnfbcc/C3v8HQoXDmmRy4bTLfRA3h6V3Fr+Ir6cdV/BvXyUrojqsuWhfVE1Ho3BmmTrWLvzGmaiLdWOxdBw7A/feDCEeem0Hjv/+dZsAtzEVLFNS+oS+t2Esnvud7OtOTNQCMe7QHr98TgbwbYxoUG2IiUmbMgB07WHDdy7SL+pFT+ZxzWMhXpXrYukAA0M9XPXTqcWsojG7EL+7oWqtZNsY0TBYIIqGgAB5/HE45hetnDWPfgcZ8yaks4pyQm/sDwR9+uRJVmHTuWqKSuwaeKzDGmOqwQBAJr78O69dzY/ZkNm4qu/snuB5Af5/VEjp3JiXa12C8Zg307Fnu54wxpqIsENQ2VXbf+xjfSjf+lVNyxI3iivUA6tsXvvnGDTedlWWBwBhTYywQ1LYFC2iz8Wv+pHeXORR0bCzMmgXZ2UE9gfr1g7VrISPDVS316FFrWTbGNGwWCGpRWhr855IZ7KA9M7k65DZlPgfQt68LAHPnumUrERhjaoh1H60laWkwfjx8lJ/JCvpzmKaltklIcKWAkPq6BmNefdX9tRKBMaaGWImglkyZAvn5kMQGNpBUan1srHsorEzdu7teQqtXQ6dOEBcXvswaYzzFAkEt2bQJmpPH8eSUCgQVGhaiceOi6iCrFjLG1CALBNX1/POwcmXp9KVLYdUq0tLc1L2qrjQAsJ4ugc381UEVGh7CXz1k1ULGmBpkgaA6du2C66+HJ58sve6aa9h+xSTGjy+aQN4fCPwlgmNWB5XUr5/7ayUCY0wNssbi6vjoI3ern5lZPL2wEL79liZHmpNf6AaKA+jimzZyPV1ISKjCQHGDB7u/AwZUP+/GGONjgaA6PvCN9V8iEMz96/dcfOgQrTlEe3LI4XjAlQhyiWM3bdmZXYXjDRsGq1ZB797VyrYxxgSzqqGqUi0KBDt2uLmFcd1E/3VvUWDoRUbgfRIbWE8XOieUP6xEuSwIGGNqmAWCqvr2W9cV6Kc/dctZWYDrJtrpUOhA0IX1bIpOqly7gDHGhJkFgqr68EP3d+JE99dXPbRpEySTST7N2EeLoECgdJENdD0/ySaQMcbUKRYIquqDD+Dkk+H88wFY8VpmoJtoMplk0ZUMegUCwaD4HcRqPj0v7FLOTo0xpvZZIKiKI0dg0SJXLRQbS37rjqz6T2agm2gymXxLt0AgiI2FP1zvuo6SVPqpYmOMiSQLBFXxxReQl1dUGshPJumoqxqKpoAurCeTZDLoxYls58U/72J4N18g6GIlAmNM3WKBoCo++ACio+HsswFYdSiZZFwgSGAjTThCJsmsoRcAV/RZA+vdMwQkJkYix8YYUyYLBFXxwQcwZAi0agVATqtk2rOTluwJBIRMktnb0QUCMjJgwwY44QT3OLExxtQhFggq68cfIT09UC0EcPpYN4l8V7ICgWBLs2QmPNrZXfgzMlyJwKqFjDF1kAWCyvrkEzeExLnnBgaUu/npZAAGxmXSjUzyJI5Hpp/AmKujoFevohKBNRQbY+ogCwSVtXAhxMby8vohgQHlsjgZcA+SXdYvk7iUZMb8yvf0cK9ebnTSTZusRGCMqZPCGghEZLiIrBORLBGZHGL9kyKy3Pf6VkT2hDM/NeKjj+CMM7jvgSbk57ukgzRjE51IPJLJ4YxMSE4u2r5XL9i+3ZUirERgjKmDwhYIRCQamAZcAPQCRotIr+BtVPUOVU1R1RTgr8Ab4cpPjfjhB1fNc845bNpUfFUmyfQig/iC7NKBwM9KBMaYOiicJYLBQJaqrlfVw8BsYGQ5248GXg5jfqrvo4/c33PPpXPn4qsySWYAX9OIo2UHAisRGGPqoHAGgo7A90HLm31ppYhIApAEfFTG+vEiki4i6Tk5OTWe0Qr76CPXZTQlhalTi/cEzSSZKNQtBAeCxESIiYFGjSA+vlaza4wxFVFXGotHAa+p6tFQK1V1uqqmqmpq+/btazlrQRYudA+RRUczZoybZzghAURgX/uuRdt161b0PjraTS2ZkODeG2NMHRPOiWm2AJ2CluN9aaGMAiaFMS/Vt2GDm1z4zjsDSWPGBM0wlpEMvXElhrZti3/29tshN7e2cmqMMZUSzkCwBEgWkSRcABgFXFVyIxHpAbQGPg9jXqrP3z5wzjmh13fp4ooGycnub7CxY8ObN2OMqYawVQ2pagFwM/A+sAZ4RVVXi8jDIjIiaNNRwGxV1XDlpUYsXAgnnkjasp4kJkJUlKv+T0vzrY+JcZPK9+8fwUwaY0zlSV2//paUmpqq6enptXvQvDzo2pUNJ59Ln+VpgecHwDUYT5/uqyLavt0ltGhRu/kzxphjEJGlqpoaal1daSyumw4cgCefdNU+27fzaOYVxYIAQH6+m54ScIPKWRAwxtQzFgjKsnevmyj+N79x1T2ff86/dl4cctOSD5cZY0x9YoGgLEuXup5Czz/v5ic+9dRSD5H5lZVujDH1gQWCsvgmo+e88wJJJR8iA7c8dWot5ssYY2qYBYKyZGW5nkAdix6GLvkQWUJCUEOxMcbUU8cMBCLyCxHxXsDIzISTT4aoqMC8A1FRrmF46lQ3mGh2tgUBY0z9V5EL/JVApoj8yffwlzdkZUHXrqSlEZh3QNX9HT8+6PkBY4yp544ZCFT1V8AA4DvgRRH53DcIXMPtJ1lYCN99B127MmUK5XcZNcaYeq5CVT6qug94DTeUdAfgEmCZiNwSxrxFzpYtcPAgJCeX2TXUuowaYxqKirQRjBCR/wAfA42Bwap6AdAfuLO8z9Zb/h5DXbtal1FjTINXkRLBZcCTqtpXVR9X1R0AqpoPXBfW3EVKVpb7m5xsXUaNMQ1eRQLBg8BX/gURaSYiiQCqujAsuYq0zExo2hTi463LqDGmwavIMNSvAkODlo/60k4JS47qgqysQNdRKDHvgDHGNDAVKRE08s05DIDvfZPwZakO8HUdNcYYL6hIIMgJnj9AREYCO8OXpQgrLLRAYIzxlIoEgpuA+0Vkk4h8D9wL3BjebEXQ1q1w8CBf/ZgcegIaY4xpYI7ZRqCq3wGnikicbzkv7LmKJF/X0Yf/3ZWNh1yS/2lisLYCY0zDU6E5i0XkItzU7DHim49XVR8OY74ix9d19JtDycWS/U8TWyAwxjQ0FXmg7B+48YZuAQS4AkgIc74iJzOTQzRhM/GlVtnTxMaYhqgibQRDVfXXwI+q+hBwGtAtvNmKoKwsNjU+mUKiS62yp4mNMQ1RRQLBQd/ffBE5CTiCG2+oYcrMpFmfrvY0sTHGMyoSCN4SkVbA48AyIBv4dzgzFTG+UUfjh3W1p4mNMZ5RbmOxb0Kahaq6B3hdRN4GYlR1b63krrZt3QoHDkBysj1NbIzxjHJLBKpaCEwLWj7UYIMAFBt11BhjvKIiVUMLReQy8fcbrQQRGS4i60QkS0Qml7HNL0UkQ0RWi0hkq5xWr3Z/e/WKaDaMMaY2VeQ5ghuB3wAFInIQ14VUVfW48j4kItG40sT5wGZgiYjMU9WMoG2SgfuA01X1RxE5vornUTMyMqBlSzjppIhmwxhjalNFniyu6pSUg4EsVV0PICKzgZFARtA2NwDTVPVH37F2VPFYNWP1alcaqHzhxxhj6q1jBgIROTNUuqp+eoyPdgS+D1reDAwpsU033zH+B0QDD6rqe8fKU9hkZMDFF0fs8MYYEwkVaSO4O+j1O+At3GQ1NaERkAwMA0YD//R1VS1GRMaLSLqIpOfk5NTQoUvYsQN27uTh13vbQHPGGE85ZiBQ1V8Evc4H+gA/VmDfW4BOQcvxvrRgm4F5qnpEVTcA3+ICQ8k8TFfVVFVNbd++fQUOXXkfPu1qrP77Yy9Uiwaas2BgjGnoKlIiKGkz0LMC2y0BkkUkSUSaAKOAeSW2mYsrDSAi7XBVReurkKdq+/QfrsfQanoH0vwDzRljTENWkTaCvwLqW4wCUnBPGJdLVQtE5GbgfVz9//OqulpEHgbSVXWeb91PRSQDNwXm3aq6q2qnUj0ddmewl+PYSvEeQzbQnDGmoatI99H0oPcFwMuq+r+K7FxV5wPzS6T9Pui94rqm/hmEB6oAABZGSURBVKYi+wungU1Xs/pQb1zv2CI20JwxpqGrSCB4DTioqkfBPR8gIrGqmh/erNWulCarmV0w0pVLfGygOWOMF1ToyWKgWdByM2BBeLITITk5xOTupO+o3jbQnDHGcypSIogJnp5SVfNEJLa8D9Q7vqElBv26N9mzIpwXY4ypZRUpEewXkYH+BREZBBwIX5YiIMP3sLONMWSM8aCKlAhuB14Vka24ltQTcVNXNhyrV8Nxx0HHjpHOiTHG1LqKjDW0RER6AN19SetU9Uh4s1XLMjJsjCFjjGdVZPL6SUBzVV2lqquAOBGZGP6s1aLVq6F372NvZ4wxDVBF2ghu8M1QBoBvpNAbwpelWpaT417WPmCM8aiKBILo4ElpfPMMNAlflmqZv6HYSgTGGI+qSGPxe8AcEfl/vuUbgXfDl6Va9vXX7m+/fpHNhzHGREhFAsG9wHjgJt/ySlzPoYZh6VLo0MG9jDHGgyoyDHUh8CWQjZt17BxgTXizVYuWLoVBgyKdC2OMiZgyA4GIdBORB0RkLfBXYBOAqp6tqn+rrQyG05zn8ihcs5YH3061iWiMMZ5VXolgLe7u/+eq+hNV/SvFhmSr39LS4J+TlhOFks4gm4jGGONZ5QWCS4FtwCIR+aeInEvJMZrrsSlToM8hN8L2UlzVkE1EY4zxojIDgarOVdVRQA9gEW6oieNF5FkR+WltZTBcNm2CQSxlKx34gQ7F0o0xxksq0li8X1X/raq/wM07/DWuJ1G91rmzCwTppJZKN8YYL6nUnMWq+qNvIvlzw5Wh2vLY7/LowdpAtRDYRDTGGG+qyuT1DcKV3V1D8fftB9lENMYYT6vIA2UNU7prKH5+xSCet2fJjDEe5tkSAUuXwkkn2RPFxhjP83YgsCeKjTHGo4EgLw/WrrVAYIwxeDUQLF8OqhYIjDEGrwaCtWvd3z59IpsPY4ypA8IaCERkuIisE5EsEZkcYv04EckRkeW+1/XhzE9Abq7726pVrRzOGGPqsrB1H/XNZDYNOB/YDCwRkXmqmlFi0zmqenO48hFSXp7727x5rR7WGGPqonCWCAYDWaq6XlUPA7OBkWE8XsXl5UHTptC4caRzYowxERfOQNAR+D5oebMvraTLRGSliLwmIp1C7UhExotIuoik5+TkVD9n+/dDXFz192OMMQ1ApBuL3wISVbUf8CEwI9RGvvGNUlU1tX379tU/al6eVQsZY4xPOAPBFiD4Dj/elxagqrtU9ZBv8V9A7fTnzMuzEoExxviEMxAsAZJFJElEmgCjgHnBG4hI8PgOI6ituZAtEBhjTEDYeg2paoGI3Ay8D0QDz6vqahF5GEhX1XnArSIyAigAdgPjwpWfYiwQGGNMQFhHH1XV+cD8Emm/D3p/H3BfOPMQUl4etG1b64c1xpi6KNKNxZFhvYaMMSbAm4HAeg0ZY0yAdwOBlQiMMQbwYiAoLLSqIWOMCeK5QDD7hQOgyr2PxJGYCGlpkc6RMcZElqcCQVoaTL5lPwC5xLFxI4wfb8HAGONtngoEU6ZA1AE38uh+XGNxfr5LN8YYr/JUINi0CeJwgSCPuGLpxhjjVZ4KBJ07hw4EnTtHKkfGGBN5ngoEU6dCu6bFA0FsrEs3xhiv8lQgGDMG7rrJ30YQR0ICTJ/u0o0xxqvCOtZQXXTmINdraHlWHJwc4cwYY0wd4KkSAWDzFRtjTAneDQT2ZLExxgBeDgSxsZHNhzHG1BHeDATNm0OU907dGGNC8d7V0AacM8aYYrwXCGwuAmOMKcabgcBKBMYYE2CBwBhjPM4CgTHGeJwFAmOM8TjvBQLrNWSMMcV4LxBYryFjjCnGm4HASgTGGBMQ1kAgIsNFZJ2IZInI5HK2u0xEVERSw5kfCgrg4EELBMYYEyRsgUBEooFpwAVAL2C0iPQKsV0L4Dbgy3DlJWC/G4LaAoExxhQJZ4lgMJClqutV9TAwGxgZYrtHgMeAg2HMi2OBwBhjSglnIOgIfB+0vNmXFiAiA4FOqvpOeTsSkfEiki4i6Tk5OVXPkc1FYIwxpURshjIRiQL+Aow71raqOh2YDpCamqpVPqjNRWBMtRw5coTNmzdz8GD4C/CmamJiYoiPj6dx48YV/kw4A8EWoFPQcrwvza8F0Af4WEQATgTmicgIVU0PS44sEBhTLZs3b6ZFixYkJibi+39r6hBVZdeuXWzevJmkpKQKfy6cVUNLgGQRSRKRJsAoYJ5/paruVdV2qpqoqonAF0D4ggBYIDCmmg4ePEjbtm0tCNRRIkLbtm0rXWILWyBQ1QLgZuB9YA3wiqquFpGHRWREuI5bLgsExlSbBYG6rSq/T1jbCFR1PjC/RNrvy9h2WDjzAhT1GrLGYmOMCfDWk8VWIjCmVqWlQWKimxk2MdEtV8euXbtISUkhJSWFE088kY4dOwaWDx8+XO5n09PTufXWW495jKFDh1Yvk/VQxHoNRYQFAmNqTVoajB8P+flueeNGtwwwZkzV9tm2bVuWL18OwIMPPkhcXBx33XVXYH1BQQGNGoW+rKWmppKaeuzBCxYvXly1zNVj3isRREdD06aRzokxDd6UKUVBwC8/36XXpHHjxnHTTTcxZMgQ7rnnHr766itOO+00BgwYwNChQ1m3bh0AH3/8MT//+c8BF0SuvfZahg0bRpcuXXjmmWcC+4vz3Sh+/PHHDBs2jMsvv5wePXowZswYVF3v9fnz59OjRw8GDRrErbfeGthvsOzsbM444wwGDhzIwIEDiwWYxx57jL59+9K/f38mT3aj72RlZXHeeefRv39/Bg4cyHfffVezX1Q5vFciiIsDa+wyJuw2bapcenVs3ryZxYsXEx0dzb59+/jss89o1KgRCxYs4P777+f1118v9Zm1a9eyaNEicnNz6d69OxMmTCjV9/7rr79m9erVnHTSSZx++un873//IzU1lRtvvJFPP/2UpKQkRo8eHTJPxx9/PB9++CExMTFkZmYyevRo0tPTeffdd3nzzTf58ssviY2NZffu3QCMGTOGyZMnc8kll3Dw4EEKCwtr/osqg7cCgc1FYEyt6dzZVQeFSq9pV1xxBdHR0QDs3buXsWPHkpmZiYhw5MiRkJ+56KKLaNq0KU2bNuX4449n+/btxMfHF9tm8ODBgbSUlBSys7OJi4ujS5cugX76o0ePZvr06aX2f+TIEW6++WaWL19OdHQ03377LQALFizgmmuuITY2FoA2bdqQm5vLli1buOSSSwD3UFht8l7VkPUYMqZWTJ0KvmtdQGysS69pzYP+X//ud7/j7LPPZtWqVbz11ltl9qlvGlRFHB0dTUFBQZW2KcuTTz7JCSecwIoVK0hPTz9mY3YkeS8QWInAmFoxZgxMnw4JCa42NiHBLVe1obii9u7dS8eOblizF198scb33717d9avX092djYAc+bMKTMfHTp0ICoqipkzZ3L06FEAzj//fF544QXyfQ0ou3fvpkWLFsTHxzN37lwADh06FFhfGywQGGPCZswYyM6GwkL3N9xBAOCee+7hvvvuY8CAAZW6g6+oZs2a8fe//53hw4czaNAgWrRoQcuWLUttN3HiRGbMmEH//v1Zu3ZtoNQyfPhwRowYQWpqKikpKTzxxBMAzJw5k2eeeYZ+/foxdOhQfvjhhxrPe1nE3wpeX6Smpmp6ehVHoUhNhRNOgHfKHezUGFOGNWvW0LNnz0hnI+Ly8vKIi4tDVZk0aRLJycnccccdkc5WQKjfSUSWqmrI/rNWIjDGmEr65z//SUpKCr1792bv3r3ceOONkc5StXiv15A1FhtjqumOO+6oUyWA6rISgTHGeJwnAkFaGiQmKEf25DFtRly1xzsxxpiGpMFXDfnHOynIP0xjCtiyL457qjneiTHGNCQNvkTgH+8kDjfgXB5xYRnvxBhj6qsGHwj845o0x81FkEdcsXRjTP1x9tln8/777xdLe+qpp5gwYUKZnxk2bBj+LucXXnghe/bsKbXNgw8+GOjPX5a5c+eSkZERWP7973/PggULKpP9OqvBBwL/uCb+EsF+mhdLN8bUH6NHj2b27NnF0mbPnl3mwG8lzZ8/n1atWlXp2CUDwcMPP8x5551XpX3VNQ0+EPjHOwmuGgrXeCfGeMrtt8OwYTX7uv32cg95+eWX88477wTG7cnOzmbr1q2cccYZTJgwgdTUVHr37s0DDzwQ8vOJiYns3LkTgKlTp9KtWzd+8pOfBIaqBveMwCmnnEL//v257LLLyM/PZ/HixcybN4+7776blJQUvvvuO8aNG8drr70GwMKFCxkwYAB9+/bl2muv5dChQ4HjPfDAAwwcOJC+ffuydu3aUnmqC8NVN/hA4B/v5OTjXSCIOyGuVsY7McbUvDZt2jB48GDeffddwJUGfvnLXyIiTJ06lfT0dFauXMknn3zCypUry9zP0qVLmT17NsuXL2f+/PksWbIksO7SSy9lyZIlrFixgp49e/Lcc88xdOhQRowYweOPP87y5cs5+eSTA9sfPHiQcePGMWfOHL755hsKCgp49tlnA+vbtWvHsmXLmDBhQsjqJ/9w1cuWLWPOnDmBWdSCh6tesWIF99xzD+CGq540aRIrVqxg8eLFdOjQoXpfKh7oNQTuoj+mRR6MhDnvxMGgSOfImAbgqaciclh/9dDIkSOZPXs2zz33HACvvPIK06dPp6CggG3btpGRkUG/fv1C7uOzzz7jkksuCQwFPWLEiMC6VatW8dvf/pY9e/aQl5fHz372s3Lzs27dOpKSkujWrRsAY8eOZdq0adzuK91ceumlAAwaNIg33nij1OfrwnDVnggEgE1TaUwDMXLkSO644w6WLVtGfn4+gwYNYsOGDTzxxBMsWbKE1q1bM27cuDKHnz6WcePGMXfuXPr378+LL77Ixx9/XK38+oeyLmsY6+DhqgsLC2t9LgLwQNVQwH7Xa8iGmDCmfouLi+Pss8/m2muvDTQS79u3j+bNm9OyZUu2b98eqDoqy5lnnsncuXM5cOAAubm5vPXWW4F1ubm5dOjQgSNHjpAW9PRpixYtyM3NLbWv7t27k52dTVZWFuBGET3rrLMqfD51Ybhq7wQCKxEY02CMHj2aFStWBAJB//79GTBgAD169OCqq67i9NNPL/fzAwcO5Morr6R///5ccMEFnHLKKYF1jzzyCEOGDOH000+nR48egfRRo0bx+OOPM2DAgGINtDExMbzwwgtcccUV9O3bl6ioKG666aYKn0tdGK7aO8NQv/kmvPQSzJ4NJeYlNcZUjA1DXT9Udhhq77QRjBzpXsYYY4oJa9WQiAwXkXUikiUik0Osv0lEvhGR5SLyXxHpFc78GGOMKS1sgUBEooFpwAVAL2B0iAv9v1W1r6qmAH8C/hKu/BhjakZ9q072mqr8PuEsEQwGslR1vaoeBmYDxepmVHVf0GJzwP6FGVOHxcTEsGvXLgsGdZSqsmvXrkp3QQ1nG0FH4Pug5c3AkJIbicgk4DdAE+CcUDsSkfHAeIDONkiQMRETHx/P5s2bycnJiXRWTBliYmKIj4+v1Gci3lisqtOAaSJyFfBbYGyIbaYD08H1GqrdHBpj/Bo3bkxSUlKks2FqWDirhrYAnYKW431pZZkNXBzG/BhjjAkhnIFgCZAsIkki0gQYBcwL3kBEkoMWLwIyw5gfY4wxIYStakhVC0TkZuB9IBp4XlVXi8jDQLqqzgNuFpHzgCPAj4SoFjLGGBNe9e7JYhHJATZW8ePtgJ01mJ36wovn7cVzBm+etxfPGSp/3gmq2j7UinoXCKpDRNLLesS6IfPieXvxnMGb5+3Fc4aaPW/vDDpnjDEmJAsExhjjcV4LBNMjnYEI8eJ5e/GcwZvn7cVzhho8b0+1ERhjjCnNayUCY4wxJVggMMYYj/NMIDjW3AgNgYh0EpFFIpIhIqtF5DZfehsR+VBEMn1/W0c6rzVNRKJF5GsRedu3nCQiX/p+7zm+p9sbFBFpJSKvichaEVkjIqd55Le+w/fve5WIvCwiMQ3t9xaR50Vkh4isCkoL+duK84zv3FeKyMDKHs8TgaCCcyM0BAXAnaraCzgVmOQ7z8nAQlVNBhb6lhua24A1QcuPAU+qalfcU+vXRSRX4fU08J6q9gD6486/Qf/WItIRuBVIVdU+uFELRtHwfu8XgeEl0sr6bS8Akn2v8cCzlT2YJwIBFZgboSFQ1W2qusz3Phd3YeiIO9cZvs1m0MAG9xOReNxYVf/yLQtuSPPXfJs0xHNuCZwJPAegqodVdQ8N/Lf2aQQ0E5FGQCywjQb2e6vqp8DuEsll/bYjgZfU+QJoJSIdKnM8rwSCUHMjdIxQXmqFiCQCA4AvgRNUdZtv1Q/ACRHKVrg8BdwDFPqW2wJ7VLXAt9wQf+8kIAd4wVcl9i8RaU4D/61VdQvwBLAJFwD2Aktp+L83lP3bVvv65pVA4CkiEge8DtxeYhY41PUXbjB9hkXk58AOVV0a6bzUskbAQOBZVR0A7KdENVBD+60BfPXiI3GB8CTczIYlq1AavJr+bb0SCCo7N0K9JSKNcUEgTVXf8CVv9xcVfX93RCp/YXA6MEJEsnFVfufg6s5b+aoOoGH+3puBzar6pW/5NVxgaMi/NcB5wAZVzVHVI8AbuH8DDf33hrJ/22pf37wSCI45N0JD4Ksbfw5Yo6p/CVo1j6IhvscCb9Z23sJFVe9T1XhVTcT9rh+p6hhgEXC5b7MGdc4AqvoD8L2IdPclnQtk0IB/a59NwKkiEuv79+4/7wb9e/uU9dvOA37t6z10KrA3qAqpYlTVEy/gQuBb4DtgSqTzE6Zz/AmuuLgSWO57XYirM1+Im/hnAdAm0nkN0/kPA972ve8CfAVkAa8CTSOdvzCcbwqQ7vu95wKtvfBbAw8Ba4FVwEygaUP7vYGXcW0gR3Clv+vK+m0BwfWK/A74BtejqlLHsyEmjDHG47xSNWSMMaYMFgiMMcbjLBAYY4zHWSAwxhiPs0BgjDEeZ4HAGB8ROSoiy4NeNTZgm4gkBo8kaUxd0ujYmxjjGQdUNSXSmTCmtlmJwJhjEJFsEfmTiHwjIl+JSFdfeqKIfOQbA36hiHT2pZ8gIv8RkRW+11DfrqJF5J++sfQ/EJFmvu1v9c0hsVJEZkfoNI2HWSAwpkizElVDVwat26uqfYG/4UY7BfgrMENV+wFpwDO+9GeAT1S1P278n9W+9GRgmqr2BvYAl/nSJwMDfPu5KVwnZ0xZ7MliY3xEJE9V40KkZwPnqOp636B+P6hqWxHZCXRQ1SO+9G2q2k5EcoB4VT0UtI9E4EN1k4ogIvcCjVX1DyLyHpCHGyZirqrmhflUjSnGSgTGVIyW8b4yDgW9P0pRG91FuLFiBgJLgkbRNKZWWCAwpmKuDPr7ue/9YtyIpwBjgM987xcCEyAwl3LLsnYqIlFAJ1VdBNwLtARKlUqMCSe78zCmSDMRWR60/J6q+ruQthaRlbi7+tG+tFtwM4TdjZst7Bpf+m3AdBG5DnfnPwE3kmQo0cAsX7AQ4Bl1U04aU2usjcCYY/C1EaSq6s5I58WYcLCqIWOM8TgrERhjjMdZicAYYzzOAoExxnicBQJjjPE4CwTGGONxFgiMMcbj/j/t+pPUhTvVNwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "Vz9GL7KPlMVk",
        "outputId": "1947dd46-9923-431a-f35a-08751e3c0a6e"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhBhpBJI6bdY"
      },
      "source": [
        "## 3. Train (again) and evaluate the model\n",
        "\n",
        "- To this end, you have found the \"best\" hyper-parameters. \n",
        "- Now, fix the hyper-parameters and train the network on the entire training set (all the 50K training samples)\n",
        "- Evaluate your model on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxffQzZu9bqg"
      },
      "source": [
        ""
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eiv2cwqo6bda"
      },
      "source": [
        "### 3.1. Train the model on the entire training set\n",
        "\n",
        "Why? Previously, you used 40K samples for training; you wasted 10K samples for the sake of hyper-parameter tuning. Now you already know the hyper-parameters, so why not using all the 50K samples for training?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvQ2cgK19dCP",
        "outputId": "32f653d0-7502-46e0-d2c9-7d14cf8bad42"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "# model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(MaxPooling2D((2, 2)))\n",
        "# model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "# model.add(Dropout(0.5))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "# model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_32 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization_37 (Batc (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_33 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_38 (Batc (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_34 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_39 (Batc (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_35 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_40 (Batc (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_22 (Dropout)         (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_36 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_41 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_37 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_42 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_18 (MaxPooling (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_23 (Dropout)         (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "batch_normalization_43 (Batc (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dropout_24 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 552,874\n",
            "Trainable params: 551,722\n",
            "Non-trainable params: 1,152\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvB2INbq9zAZ"
      },
      "source": [
        "learning_rate = 0.001 # to be tuned!\n",
        "\n",
        "model.compile(loss='CategoricalCrossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=learning_rate),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_L_SubT90H2",
        "outputId": "2943c365-24e3-4214-885e-b67483ce318c"
      },
      "source": [
        "datagen = ImageDataGenerator(width_shift_range = 0.1, height_shift_range = 0.1, horizontal_flip = True, )\n",
        "# it_train = datagen.flow(x_tr, y_tr, 512)\n",
        "datagen.fit(x_train)\n",
        "\n",
        "history = model.fit(datagen.flow(x_train, y_train_vec, batch_size=512),\n",
        "    epochs=100)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "98/98 [==============================] - 23s 218ms/step - loss: 2.3107 - acc: 0.2772\n",
            "Epoch 2/100\n",
            "98/98 [==============================] - 21s 210ms/step - loss: 1.5281 - acc: 0.4657\n",
            "Epoch 3/100\n",
            "98/98 [==============================] - 21s 209ms/step - loss: 1.2709 - acc: 0.5575\n",
            "Epoch 4/100\n",
            "98/98 [==============================] - 21s 211ms/step - loss: 1.1081 - acc: 0.6160\n",
            "Epoch 5/100\n",
            "98/98 [==============================] - 21s 209ms/step - loss: 0.9784 - acc: 0.6581\n",
            "Epoch 6/100\n",
            "98/98 [==============================] - 21s 210ms/step - loss: 0.8945 - acc: 0.6896\n",
            "Epoch 7/100\n",
            "98/98 [==============================] - 21s 210ms/step - loss: 0.8254 - acc: 0.7121\n",
            "Epoch 8/100\n",
            "98/98 [==============================] - 21s 210ms/step - loss: 0.7874 - acc: 0.7244\n",
            "Epoch 9/100\n",
            "98/98 [==============================] - 21s 211ms/step - loss: 0.7438 - acc: 0.7450\n",
            "Epoch 10/100\n",
            "98/98 [==============================] - 21s 211ms/step - loss: 0.7119 - acc: 0.7534\n",
            "Epoch 11/100\n",
            "98/98 [==============================] - 21s 209ms/step - loss: 0.6881 - acc: 0.7654\n",
            "Epoch 12/100\n",
            "98/98 [==============================] - 21s 210ms/step - loss: 0.6536 - acc: 0.7719\n",
            "Epoch 13/100\n",
            "98/98 [==============================] - 21s 210ms/step - loss: 0.6397 - acc: 0.7778\n",
            "Epoch 14/100\n",
            "98/98 [==============================] - 21s 210ms/step - loss: 0.6213 - acc: 0.7892\n",
            "Epoch 15/100\n",
            "98/98 [==============================] - 21s 210ms/step - loss: 0.6078 - acc: 0.7903\n",
            "Epoch 16/100\n",
            "98/98 [==============================] - 21s 210ms/step - loss: 0.5779 - acc: 0.8022\n",
            "Epoch 17/100\n",
            "98/98 [==============================] - 21s 209ms/step - loss: 0.5663 - acc: 0.8031\n",
            "Epoch 18/100\n",
            "98/98 [==============================] - 21s 209ms/step - loss: 0.5538 - acc: 0.8133\n",
            "Epoch 19/100\n",
            "98/98 [==============================] - 21s 209ms/step - loss: 0.5461 - acc: 0.8111\n",
            "Epoch 20/100\n",
            "98/98 [==============================] - 21s 211ms/step - loss: 0.5326 - acc: 0.8192\n",
            "Epoch 21/100\n",
            "98/98 [==============================] - 21s 210ms/step - loss: 0.5283 - acc: 0.8222\n",
            "Epoch 22/100\n",
            "98/98 [==============================] - 21s 210ms/step - loss: 0.5186 - acc: 0.8221\n",
            "Epoch 23/100\n",
            "98/98 [==============================] - 21s 211ms/step - loss: 0.5176 - acc: 0.8240\n",
            "Epoch 24/100\n",
            "98/98 [==============================] - 21s 212ms/step - loss: 0.4949 - acc: 0.8304\n",
            "Epoch 25/100\n",
            "98/98 [==============================] - 21s 210ms/step - loss: 0.4764 - acc: 0.8335\n",
            "Epoch 26/100\n",
            "98/98 [==============================] - 21s 209ms/step - loss: 0.4883 - acc: 0.8341\n",
            "Epoch 27/100\n",
            "98/98 [==============================] - 21s 209ms/step - loss: 0.4725 - acc: 0.8377\n",
            "Epoch 28/100\n",
            "98/98 [==============================] - 21s 212ms/step - loss: 0.4685 - acc: 0.8385\n",
            "Epoch 29/100\n",
            "98/98 [==============================] - 21s 209ms/step - loss: 0.4577 - acc: 0.8409\n",
            "Epoch 30/100\n",
            "98/98 [==============================] - 21s 212ms/step - loss: 0.4544 - acc: 0.8441\n",
            "Epoch 31/100\n",
            "98/98 [==============================] - 21s 211ms/step - loss: 0.4430 - acc: 0.8496\n",
            "Epoch 32/100\n",
            "98/98 [==============================] - 21s 209ms/step - loss: 0.4477 - acc: 0.8483\n",
            "Epoch 33/100\n",
            "98/98 [==============================] - 21s 210ms/step - loss: 0.4378 - acc: 0.8489\n",
            "Epoch 34/100\n",
            "98/98 [==============================] - 21s 210ms/step - loss: 0.4406 - acc: 0.8480\n",
            "Epoch 35/100\n",
            "98/98 [==============================] - 20s 208ms/step - loss: 0.4308 - acc: 0.8529\n",
            "Epoch 36/100\n",
            "98/98 [==============================] - 21s 212ms/step - loss: 0.4263 - acc: 0.8551\n",
            "Epoch 37/100\n",
            "98/98 [==============================] - 20s 208ms/step - loss: 0.4230 - acc: 0.8547\n",
            "Epoch 38/100\n",
            "98/98 [==============================] - 21s 212ms/step - loss: 0.4209 - acc: 0.8554\n",
            "Epoch 39/100\n",
            "98/98 [==============================] - 21s 213ms/step - loss: 0.4172 - acc: 0.8575\n",
            "Epoch 40/100\n",
            "98/98 [==============================] - 21s 210ms/step - loss: 0.4037 - acc: 0.8615\n",
            "Epoch 41/100\n",
            "98/98 [==============================] - 21s 210ms/step - loss: 0.4030 - acc: 0.8619\n",
            "Epoch 42/100\n",
            "98/98 [==============================] - 21s 210ms/step - loss: 0.3933 - acc: 0.8666\n",
            "Epoch 43/100\n",
            "98/98 [==============================] - 21s 210ms/step - loss: 0.3920 - acc: 0.8650\n",
            "Epoch 44/100\n",
            "98/98 [==============================] - 21s 210ms/step - loss: 0.3931 - acc: 0.8659\n",
            "Epoch 45/100\n",
            "98/98 [==============================] - 21s 210ms/step - loss: 0.3881 - acc: 0.8686\n",
            "Epoch 46/100\n",
            "98/98 [==============================] - 21s 210ms/step - loss: 0.3892 - acc: 0.8658\n",
            "Epoch 47/100\n",
            "98/98 [==============================] - 21s 211ms/step - loss: 0.3787 - acc: 0.8698\n",
            "Epoch 48/100\n",
            "98/98 [==============================] - 21s 210ms/step - loss: 0.3723 - acc: 0.8725\n",
            "Epoch 49/100\n",
            "98/98 [==============================] - 21s 210ms/step - loss: 0.3862 - acc: 0.8673\n",
            "Epoch 50/100\n",
            "98/98 [==============================] - 21s 210ms/step - loss: 0.3710 - acc: 0.8748\n",
            "Epoch 51/100\n",
            "98/98 [==============================] - 21s 211ms/step - loss: 0.3748 - acc: 0.8734\n",
            "Epoch 52/100\n",
            "98/98 [==============================] - 21s 209ms/step - loss: 0.3662 - acc: 0.8737\n",
            "Epoch 53/100\n",
            "98/98 [==============================] - 21s 212ms/step - loss: 0.3669 - acc: 0.8741\n",
            "Epoch 54/100\n",
            "98/98 [==============================] - 21s 211ms/step - loss: 0.3662 - acc: 0.8743\n",
            "Epoch 55/100\n",
            "98/98 [==============================] - 21s 210ms/step - loss: 0.3600 - acc: 0.8767\n",
            "Epoch 56/100\n",
            "98/98 [==============================] - 21s 210ms/step - loss: 0.3617 - acc: 0.8744\n",
            "Epoch 57/100\n",
            "98/98 [==============================] - 21s 210ms/step - loss: 0.3605 - acc: 0.8744\n",
            "Epoch 58/100\n",
            "98/98 [==============================] - 21s 210ms/step - loss: 0.3557 - acc: 0.8790\n",
            "Epoch 59/100\n",
            "98/98 [==============================] - 21s 210ms/step - loss: 0.3431 - acc: 0.8818\n",
            "Epoch 60/100\n",
            "98/98 [==============================] - 21s 210ms/step - loss: 0.3466 - acc: 0.8820\n",
            "Epoch 61/100\n",
            "98/98 [==============================] - 21s 209ms/step - loss: 0.3501 - acc: 0.8806\n",
            "Epoch 62/100\n",
            "98/98 [==============================] - 21s 210ms/step - loss: 0.3429 - acc: 0.8829\n",
            "Epoch 63/100\n",
            "98/98 [==============================] - 21s 211ms/step - loss: 0.3525 - acc: 0.8811\n",
            "Epoch 64/100\n",
            "98/98 [==============================] - 21s 209ms/step - loss: 0.3438 - acc: 0.8813\n",
            "Epoch 65/100\n",
            "98/98 [==============================] - 21s 211ms/step - loss: 0.3400 - acc: 0.8831\n",
            "Epoch 66/100\n",
            "98/98 [==============================] - 21s 211ms/step - loss: 0.3417 - acc: 0.8817\n",
            "Epoch 67/100\n",
            "98/98 [==============================] - 21s 218ms/step - loss: 0.3397 - acc: 0.8833\n",
            "Epoch 68/100\n",
            "98/98 [==============================] - 21s 219ms/step - loss: 0.3273 - acc: 0.8865\n",
            "Epoch 69/100\n",
            "98/98 [==============================] - 21s 215ms/step - loss: 0.3427 - acc: 0.8811\n",
            "Epoch 70/100\n",
            "98/98 [==============================] - 21s 211ms/step - loss: 0.3283 - acc: 0.8875\n",
            "Epoch 71/100\n",
            "98/98 [==============================] - 21s 213ms/step - loss: 0.3278 - acc: 0.8883\n",
            "Epoch 72/100\n",
            "98/98 [==============================] - 21s 211ms/step - loss: 0.3330 - acc: 0.8869\n",
            "Epoch 73/100\n",
            "98/98 [==============================] - 21s 213ms/step - loss: 0.3226 - acc: 0.8893\n",
            "Epoch 74/100\n",
            "98/98 [==============================] - 21s 213ms/step - loss: 0.3171 - acc: 0.8914\n",
            "Epoch 75/100\n",
            "98/98 [==============================] - 21s 213ms/step - loss: 0.3293 - acc: 0.8866\n",
            "Epoch 76/100\n",
            "98/98 [==============================] - 21s 211ms/step - loss: 0.3129 - acc: 0.8908\n",
            "Epoch 77/100\n",
            "98/98 [==============================] - 21s 211ms/step - loss: 0.3184 - acc: 0.8918\n",
            "Epoch 78/100\n",
            "98/98 [==============================] - 21s 211ms/step - loss: 0.3219 - acc: 0.8883\n",
            "Epoch 79/100\n",
            "98/98 [==============================] - 21s 214ms/step - loss: 0.3136 - acc: 0.8925\n",
            "Epoch 80/100\n",
            "98/98 [==============================] - 21s 214ms/step - loss: 0.3210 - acc: 0.8890\n",
            "Epoch 81/100\n",
            "98/98 [==============================] - 21s 210ms/step - loss: 0.3139 - acc: 0.8915\n",
            "Epoch 82/100\n",
            "98/98 [==============================] - 21s 211ms/step - loss: 0.3207 - acc: 0.8891\n",
            "Epoch 83/100\n",
            "98/98 [==============================] - 21s 213ms/step - loss: 0.3126 - acc: 0.8919\n",
            "Epoch 84/100\n",
            "98/98 [==============================] - 21s 211ms/step - loss: 0.3117 - acc: 0.8924\n",
            "Epoch 85/100\n",
            "98/98 [==============================] - 21s 212ms/step - loss: 0.3116 - acc: 0.8910\n",
            "Epoch 86/100\n",
            "98/98 [==============================] - 21s 211ms/step - loss: 0.3113 - acc: 0.8957\n",
            "Epoch 87/100\n",
            "98/98 [==============================] - 21s 211ms/step - loss: 0.3087 - acc: 0.8960\n",
            "Epoch 88/100\n",
            "98/98 [==============================] - 21s 212ms/step - loss: 0.3085 - acc: 0.8930\n",
            "Epoch 89/100\n",
            "98/98 [==============================] - 21s 210ms/step - loss: 0.2996 - acc: 0.8965\n",
            "Epoch 90/100\n",
            "98/98 [==============================] - 21s 211ms/step - loss: 0.2881 - acc: 0.9009\n",
            "Epoch 91/100\n",
            "98/98 [==============================] - 21s 210ms/step - loss: 0.3010 - acc: 0.8960\n",
            "Epoch 92/100\n",
            "98/98 [==============================] - 21s 211ms/step - loss: 0.3051 - acc: 0.8946\n",
            "Epoch 93/100\n",
            "98/98 [==============================] - 21s 210ms/step - loss: 0.2995 - acc: 0.8967\n",
            "Epoch 94/100\n",
            "98/98 [==============================] - 21s 212ms/step - loss: 0.2985 - acc: 0.8956\n",
            "Epoch 95/100\n",
            "98/98 [==============================] - 21s 211ms/step - loss: 0.3010 - acc: 0.8966\n",
            "Epoch 96/100\n",
            "98/98 [==============================] - 21s 210ms/step - loss: 0.2949 - acc: 0.8964\n",
            "Epoch 97/100\n",
            "98/98 [==============================] - 21s 212ms/step - loss: 0.3001 - acc: 0.8977\n",
            "Epoch 98/100\n",
            "98/98 [==============================] - 21s 212ms/step - loss: 0.2928 - acc: 0.9016\n",
            "Epoch 99/100\n",
            "98/98 [==============================] - 21s 211ms/step - loss: 0.2940 - acc: 0.8984\n",
            "Epoch 100/100\n",
            "98/98 [==============================] - 21s 211ms/step - loss: 0.2921 - acc: 0.8984\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AncNgIww6bdb"
      },
      "source": [
        "<Compile your model again (using the same hyper-parameters)>\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-R_Qm49f6bdc"
      },
      "source": [
        "<Train your model on the entire training set (50K samples)>\n",
        "<Use (x_train, y_train_vec) instead of (x_tr, y_tr)>\n",
        "<Do NOT use the validation_data option (because now you do not have validation data)>\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPpstA_S6bdd"
      },
      "source": [
        "### 3.2. Evaluate the model on the test set\n",
        "\n",
        "Do NOT used the test set until now. Make sure that your model parameters and hyper-parameters are independent of the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIdydrJQ6bdd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2241ffb-f77b-416d-9f93-e7ce6de20140"
      },
      "source": [
        "loss_and_acc = model.evaluate(x_test, y_test_vec)\n",
        "print('loss = ' + str(loss_and_acc[0]))\n",
        "print('accuracy = ' + str(loss_and_acc[1]))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.4662 - acc: 0.8603\n",
            "loss = 0.4662163555622101\n",
            "accuracy = 0.8603000044822693\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDcleuuQ6bde"
      },
      "source": [
        ""
      ],
      "execution_count": 41,
      "outputs": []
    }
  ]
}